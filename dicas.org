y# -*- coding: utf-8 after-save-hook: (lambda nil (org-html-export-to-html)) -*-
#+INFOJS_OPT: path:org-info.js view:overview toc:nil ltoc:nil
#+OPTIONS: H:2
#+STARTUP: showeverything
#+LANGUAGE: pt
#+HTML_HEAD: <link href="https://fonts.googleapis.com/css?family=Ubuntu:400,700" rel="stylesheet" type="text/css">
#+HTML_HEAD_EXTRA: <link rel="stylesheet" type="text/css" href="https://urionlinejudge.r.worldssl.net/repository/contest.css" />
#+HTML_HEAD_EXTRA: <style type="text/css"> p{ margin-top: 1em; margin-bottom: 1em; } </style>
#+TITLE: Clube de Programação
#+SUBTITLE: Repositório de Dicas para Problemas
#+AUTHOR: Leandro Zatesko, João Paulo Castilho

Os problemas a seguir não estão ordenados nem lexicográfica nem
numericamente, mas por ordem de inclusão neste arquivo. Utilize as
ferramentas de seu navegador para localizar as dicas para um problema
específico.

Achou algum erro ou tem alguma consideração sobre alguma coisa nesta
página? Mande-nos um [[mailto:jpwbernardi@hotmail.com][email]].

Esta página foi desenvolvida com o [[http://orgmode.org/][Org Mode]] do [[https://www.gnu.org/software/emacs/][Emacs]].

* DICAS GERAIS

  - Pratique muito, tanto sozinho quanto com seu time! Nada de "dividir"
    os tópicos entre os membros do time! Todos precisam ser bons em
    tudo, ou o time não conseguirá compor soluções que envolvem vários
    conteúdos! Você precisa desenvolver suas habilidades de codar rápido
    e codar certo.

  - Nos treinos, simule todas as condições da competição. Que o time use
    só uma máquina para codar, e outras máquinas só para ler os
    problemas, e que o material de consulta seja apenas o impresso (já
    vá organizando seu caderninho!)

  - Nunca ocupe a máquina se você não tem uma solução completamente
    pronta (esboçada no papel ou na sua cabeça) para codar, com a
    garantia de que ela está correta e de que tem a complexidade
    esperada (dimensionar o quanto sua solução vai consumir de tempo e
    de memória é importantíssimo! não perca tempo codando algo
    impossível de passar no time limit!)

  - É estratégia dominante para minimizar a soma dos tempos das
    submissões aceitas (e, portanto, maximizar o número de problemas
    passados na prova) resolver primeiro os problemas mais fáceis (ou
    melhor, que o time leva menos tempo para passar). Então, comecem
    cada um trabalhando num problema diferente, revezando-se no uso da
    máquina, e deixem para concentrar esforços de dois ou mais
    integrantes trabalhando num só problema mais para o final da
    prova. No começo, pegue cada um uma parte da prova para ler e achar
    rápido os problemas mais fáceis. Fique também sempre atento ao
    placar, para ver o que os outros times estão resolvendo (isso pode
    ser um indicativo de quais são os problemas mais fáceis!)

  - Após não conseguir resolver um problema na competição ou no treino,
    estude o conteúdo referente àquele problema durante a semana e tente
    novamente até conseguir passá-lo. Perseverar é importantíssimo.

  - O ideal é ter um treino zerado antes do próximo treino. Se acontecer
    de ficarem alguns problemas para trás, foque primeiro nos problemas
    do treino corrente, depois ponha sua lição de casa em dia.

  - Devore livros e materiais específicos de Programação Competitiva,
    especialmente [[http://cpbook.net/][este livro]].

  - Não leia as dicas de um problema sem antes refletir sobre o problema
    o suficiente. Se você treina no sábado, sugiro pelo menos no domingo
    ainda tentar resolver os problemas sem as dicas. Abra as dicas
    apenas na segunda-feira, e olhe códigos na Internet apenas em último
    caso ;)

  - Após passar um problema, veja códigos na Internet e dos seus colegas
    que também passaram um problema para ver como você poderia ter feito
    diferente (mais simples, mais curto, mais elegante, menos propenso a
    bugs).

  - Não seja malloqueiro! Deixe a STL do C++ cuidar da alocação dinâmica
    para você quando precisar dela! Desenvolva práticas de código que
    ajudem no debug, se você precisar! Algumas sugestões:

    -- Escreva uma função do começo ao fim, deixando para implementar as
    subrotinas depois.

    -- Modularize seu código para que as funções sejam curtas, bem
    escritas, sem precisar de comentários para serem legíveis, e sem um
    número exagerado de níveis de indentação.

    -- Jamais escreva uma porção de código que faz a mesma coisa
    trocando apenas os papéis das variáveis. Estruture melhor suas
    macros e os cabeçalhos das funções então (e.g. movimentos das peças
    do xadrez!)

    -- Defina constantes no cabeçalho do código, ao invés de colocar
    números absolutos nas funções.

    -- Use alocação estática sempre que puder, e sempre com folga nos
    tamanhos dos arrays.

    -- Trabalhe com inteiros sempre que puder, tomando sempre o cuidado
    com somas e produtos acumulados (eles cabem em 32 bits?)

* URI 2006 Identifying Tea

  Dispensa dicas.

* URI 1961 Jumping Frog

  Dispensa dicas.

* URI 1847 Welcome to the Winter!

  Dispensa dicas. Só tome cuidado para ler o problema e garantir que
  você interpretando os casos corretamente ;)

* URI 1563 The Big Problem

  Se fixamos um $N$ e um $A\in\{1,N\}$, o número de pares $(A,B)$ tais
  que $B>1$ e $B\leq N\mathbin{\text{mod}} A$ é obviamente
  $N\mathbin{\text{mod}} A$. Então, o que o problema pede, dado $N$, é
  simplesmente a fração $\rho(N)/N^2$, simplificada usando o
  [[https://en.wikipedia.org/wiki/Euclidean_algorithm][Algoritmo de Euclides]]
  (Cuidado, porque a resposta pode não caber em 32 bits!),
  sendo
  $\rho(N)=\sum_{i=1}^N(N\mathbin{\text{mod}} i)$. Como
  $N\leq 10^8$, computar $S(N)$ de um modo ingênuo é inviável, mesmo
  que a entrada consistisse de um só caso de teste. Vamos precisar
  manipular $\rho(N)$ um pouco.

  Primeiro observemos que
  $(N\mathbin{\text{mod}} i) - ((N-1)\mathbin{\text{mod}} i)$ é:
  $1$, se $i$ não
  divide $N$; $1-i$, caso contrário. Assim, tentando estabelecer uma
  recorrência para $\rho(N)$ (lembrando que $\sigma(N)$ é a soma dos
  divisores de $N$):

  \begin{gather*}
  \rho(N)-\rho(N-1) = \sum_{i\text{ não divisor de }N}1
  +\sum_{i\text{ divisor próprio de }N}(1-i)
  = \sum_{i=1}^{N-1}1-\sum_{i\text{ divisor próprio de }N}i\\
  = N - 1 - \sum_{i\text{ divisor de }N}i + N = 2N - 1 - \sigma(N)
  \end{gather*}

  Então, a recorrência é:
  $\rho(N) = 2N-1-\sigma(N)+\rho(N - 1)$. Resolvendo:

  \begin{equation*}
  \rho(N) = \sum_{i=1}^N(2i-1-\sigma(i))
  =2\sum_{i=1}^Ni-N-\sum_{i=1}^N\sigma(i)=N^2-\sum_{i=1}^N\sigma(i)
  \end{equation*}

  Então, nosso problema agora se resume a computar
  $\sum_{i=1}^N\sigma(i)$. Uma vez computada essa soma, podemos obter
  $\rho(N)$ em $O(1)$. Deixo a cargo de vocês agora
  [[http://mathoverflow.net/questions/195325/how-to-calculate-the-sum-of-remainders-of-n][pesquisar]] como
  calcular essa soma em tempo $O(\sqrt N)$ ;)

  - Complexidade: $O(\sqrt N)$

* URI 1137 Cocircular Points

  O que o problema pede, dado um conjunto de pontos, é o maior número de
  pontos que são cocirculares. O que se deve ter em mente é que cada
  conjunto de pontos não-colineares (podemos verificar facilmente se
  três
  pontos são colineares através de produto vetorial) define uma única
  circunferência.
  Então, iterando sobre todos os conjuntos de três pontos
  não-colineares, podemos simplesmente adicionar ao final de um vetor a
  circunferência definida
  por estes três pontos. No final, ordenando o vetor,
  podemos verificar que, se uma mesma circunferência
  aparecer $k$ vezes no vetor, podemos obter o número $p$ de pontos da
  entrada
  que
  pertencem a esta circunferência através da equação $k=\binom p3$ (dica
  extra pra resolver a equação: busca na 3^a
  coluna do Triângulo de Pascal).

  - Complexidade: como no pior caso cada tripla de pontos pode definir
    uma circunferência distinta, $O(N^3\log N)$. Embora eu mesmo tenha
    submetido um código $O(N^4)$ no URI (não meu) e passado :P

* URI 1863 Ramsay's Counter-attack

  #+BEGIN_QUOTE
  /Dicas escritas pelo Prof. Ricardo Oliveira, autor do problema./
  #+END_QUOTE

  O problema pode ser resolvido por programação dinâmica. Cada estado consiste
  apenas de um soldado $[u]$, e responde o tamanho da maior sequência terminando
  nele. Seu cálculo é dado por $1 + \max(PD[u'])$, onde $u'$ é um soldado posicionado a
  sudoeste de $u$ e é mais forte que $u$.

  Entretanto, o cálculo de cada estado não pode ser feito em tempo
  linear em $N$, uma vez    que isto tornaria todo o algoritmo
  quadrático em $N$.

  Entretanto, é possível manter um conjunto $S$, tal que, quando o
  estado $[u]$
  for
  visitado, $S$ contém exatamente todos os soldados mais fortes que
  $u$. Para tal, é
  possível inverter o grafo dado (i.e. criar um arco $i\to j$ quando $i$
  é mais fraco
  que $j$).
  Note que este grafo é uma floresta. É feita então uma busca em
  profundidade (DFS).
  Quando o vértice $u$ for visitado, o conjunto $S$
  será dado pelos vértices atualmente
  na pilha. Logo, um vértice deve ser incluído em $S$
  ao ser empilhado, e removido de
  $S$ ao ser desempilhado.

  Por fim, é necessário, em cada estado $[u]$,
  consultar os vértices que estão em $S$
  e que estão a sudoeste de $u$.
  Isto pode ser feito com uma árvore de segmentos
  2D.
  As respostas dos estados $[u']$ são inseridas (removidas) da
  estrutura quando o vértice é inserido em (removido de) $S$.
  O máximo das respostas
  dos vértices a sudoeste de $u$
  é dado pela consulta pelo retângulo
  $[-400,-400,x[u]-1, y[u]-1]$.

  Embora a Quad-tree também possa ser utilizada, sua constante é consideravelmente
  maior que a árvore de segmentos,
  o que pode ocasionar em TLE, dependendo da
  implementação.

  - Complexidade: $O(N\log^2(800)) = O(N)$ considerando uma constante.

* URI 1753 Knights Of The Round Table

  Este foi o Problema K da Nacional de 2014. Veja a discussão
  sobre ele [[http://codeforces.com/blog/entry/14650][neste link]].

* URI 1491 Blogger Language

  Este foi o Problema B da Nacional de 2013. Veja comentários
  sobre ele
  [[https://chococontest.wordpress.com/2013/11/15/solucionario-regional-south-america-2013/][neste link]].

* URI 1427 The Scrooge Co Problem

  O problema em questão é o clássico
  Weighted SSSP (Single-Source Shortest
  Path), pedindo para imprimir também o caminho, não só o custo do
  caminho mínimo.
  Se resolver com Dijkstra, passa tranquilamente. No entanto,
  observe que o grafo é pequeno (menos de 100 vértices) e que são também
  poucos casos de teste (menos de 100). Assim, até Floyd-Warshall deve
  passar, e o código do Floyd-Warshall é mais simples e mais curto (4
  linhas!) que o código do Dijkstra, sendo bem tranquilo também
  recuperar o caminho com o Floyd-Warshall.

  - Complexidade: $O(N^3)$

* URI 1915 Help Chaves

  Crie um grafo bipartido $(A\cup B,E)$ em que $A$ seja o conjunto dos
  $N$ amigos e $B$ o conjunto dos $M$ brinquedos. Para cada par
  $(a,b)\in A\times B$, calcule (via PD) a "distância de edição"
  de $a$
  para $b$. Se essa distância for um número múltiplo de 5, crie a
  aresta; senão, não. Depois de o grafo estar montado, é só rodar seu
  algoritmo preferido de emparelhamentos máximos em grafos bipartidos
  (até FFEK serve!).

  - Complexidade: $O(100^2NM)$ para montar o grafo (o $100^2$ é o custo
    de cada PD, já que as palavras têm no máximo 100 caracteres)
    $+$ $O(NM)$ para o FFEK. Não fique com medo de $100^2NM$ ser
    $\approx 10^8$ no pior caso de $N$ e de $M$ ;)

* UVA 13018 Dice Cup

  Problema muito fácil. Perceba que os valores de $N$ e de $M$ são
  pequenos. Então, testar todas as possibilidades de soma entre os
  inteiros e ver quais são as que mais ocorrem é totalmente factível.

  Se você ainda é iniciante e tem dificuldade em implementar esta
  solução, vou dar um pouco mais de detalhes: Crie um vetor $V$
  de inteiros com
  pelo menos 40 posições, já que 40 é o
  valor máximo  possível para uma soma de dois d20. Em cada caso de
  teste, zere esse vetor. Então, comece um for sobre uma variável $i$ de
  1 até $N$ e aninhe dentro desse for um for sobre uma variável $j$ de 1
  até $M$, incrementando $V[i+j]$ a cada iteração. No final, basta
  varrer todo o vetor $V$ para identificar qual valor ocorre mais vezes
  (ou seja, qual índice $i$ tem $V[i]$ máximo)
  e varrer uma segunda vez para imprimir todos os valores que ocorrem
  esse número máximo de vezes.

  Para imprimir uma linha de branco entre casos de teste consecutivos,
  você pode utilizar uma flag ~first~ (que começa valendo 1)
  e, antes de dar a saída para um caso
  de teste, fazer:

  #+BEGIN_SRC cpp
  if (first) first = 0;
  else printf("\n");
  #+END_SRC

  - Complexidade: $O(NM)$.

* UVA 13025 Back to the Past

  Dispensa comentários :P

* UVA 665 False Coins

  Dicas podem ser encontradas na página 40 do livro dos Halim (3^a
  edição).

* UVA 12005 Bubble Sort

  Assumamos sem perda de generalidade que estamos trabalhando com uma
  permutação $\pi$ de $\{1,\dotsc,n\}$ tomada sob distribuição
  uniforme (o problema garante que você pode assumir que os inteiros no
  array são todos distintos, o que facilita).
  Seja $X$ a [[https://en.wikipedia.org/wiki/Random_variable][variável aleatória]] que assume o número de inversões numa
  dada permutação $\pi$, i.e. o número de pares $(i,j)$ tais que
  $i < j$
  e $\pi(i) > \pi(j)$. É óbvio que o que o problema pede, o número
  esperado de trocas do [[https://en.wikipedia.org/wiki/Bubble_sort][Bubble Sort]] para ordenar $\pi$, é
  $\mathbb E(X)$, i.e. o [[https://en.wikipedia.org/wiki/Expected_value][valor esperado]] de $X$. Sendo
  $Y_{ij}$ a variável aleatória que assume o valor 1 se o par $(i,j)$ é
  uma inversão, ou 0 caso contrário, temos obviamente que

  \begin{equation*}
  \mathbb E(X) = \mathbb E\biggl(\sum_{i}\sum_{j>i} Y_{ij}\biggr).
  \end{equation*}

  Da [[https://en.wikipedia.org/wiki/Expected_value#Linearity][linearidade da esperança]]:

  \begin{equation*}
  \mathbb E(X) = \sum_{i}\sum_{j>i} \mathbb E(Y_{ij}).
  \end{equation*}

  Deixo como exercício você continuar as contas e fechar uma fórmula
  $O(1)$ em função de $n$ para $\mathbb E(X)$.

  - Complexidade: $O(1)$ para o cálculo de $E(X)$ (denominador e
    numerador) $+$ $O(\log n)$ para o
    Algoritmo de Euclides (para simplificar a fração).

* UVA 11048 Automatic Correction of Misspellings

  Calouros, vocês têm totais condições para fazer este problema!
  Este problema não requer nenhum conhecimento especial para ser
  resolvido. Os mais experientes talvez tentariam aplicar a PD da
  distância de edição aqui, mas definitivamente não é necessário.

  Note que tanto o número de palavras no dicionário quanto o número de
  consultas é pequeno neste problema, assim como o tamanho das palavras
  envolvidas na brincadeira. Então, não precisam ser tão preciosistas
  em relação à complexidade da solução. A solução que eu apresento a
  seguir é a mais simples possível. Soluções mais eficientes existem,
  mas esta aqui já passa (e tranquilamente!).

  Para cada /query/ $s$, simplesmente itere sobre todas as palavras $w$ do
  dicionário. Se $s=w$ (pode usar a ~strcmp()~ da ~string.h~),
  aborte o laço ($s$ is correct). Se você
  conseguiu identificar que $s$ é /misspelling/ de $w$ (já vou explicar
  como fazer isso), memorize isso, mas não aborte o laço (pois pode ser
  que $s$ seja igual a um outro $w$ mais pra frente).

  Implementar a função que verifica se uma palavra $s_1$ é uma
  /misspelling/ de uma palavra $s_2$ pode ser um pouco complicado para
  iniciantes. É bem possível que você até consiga fazer o serviço, mas
  que seu código fique bem complicado. Nestas horas, pensar em recursão
  pode ajudar. A seguir apresento a minha função, que recebe duas
  strings $s_1$
  e $s_2$, de tamanhos respectivamente $t_1$ e $t_2$,
  e verifica se a string definida a partir da
  posição $i$ de $s_1$ é uma /misspelling/ da string definida a partir da
  posição $j$ de $s_2$. Na hora de chamar, é só fazer:

  #+BEGIN_SRC cpp
  if (misspelling(str, 0, strlen(str), word[i], 0, strlen(word[i]) // ...
  #+END_SRC

  Por favor, tente você desenvolver sua própria função. Olhe meu código
  só quando você já conseguir ter feito o seu, para ver como você
  poderia ter feito diferente. Tente também desenvolver um código
  iterativo (que no fim das contas não vai ser muito diferente do
  recursivo).

  #+BEGIN_SRC cpp
  int misspelling(char *s1, int i, int t1, char *s2, int j, int t2) {
    if (i == t1) return j == t2 - 1;
    if (j == t2) return i == t1 - 1;
    return !strcmp(s1 + i + 1, s2 + j) || !strcmp(s1 + i, s2 + j + 1) ||
      (s1[i] != s2[j] && !strcmp(s1 + i + 1, s2 + j + 1)) ||
      (s1[i] != s2[j] && s1[i] == s2[j + 1] && s1[i + 1] == s2[j] &&
       !strcmp(s1 + i + 2, s2 + j + 2)) || // sem perigo de seg fault :)
      (s1[i] == s2[j] && misspelling(s1, i + 1, t1, s2, j + 1, t2));
  }
  #+END_SRC

  - Complexidade: $O(nm\times 25^2)$; o $25^2$ se deve ao custo
    $O(t_1t_2)$ da minha função ~misspelling()~

* UVA 10739 String to Palindrome

  Este problema é muito fácil se você já conhece PD e
  [[https://en.wikipedia.org/wiki/Levenshtein_distance][distância de edição]] (e o clássico algoritmo de
  [[https://en.wikipedia.org/wiki/Needleman%E2%80%93Wunsch_algorithm][Needleman-Wunsch]]).
  Basta lembrar que um palíndromo é uma palavra
  igual ao seu reverso. Então, é evidente que
  a distância de edição de uma
  palavra até seu reverso seja o dobro da menor distância de edição
  desta palavra para algum palíndromo.

  - Complexidade: $O(1000^2)$, já que 1000 é o comprimento máximo de uma
    palavra da entrada.

* UVA 10192 Vacation

  Leia a Seção 6.5.2 (Longest Common Subsequence, LCS --- não confundir com
  Longest Common Substring, que também é abreviado LCS) do livro dos
  Halim, que reduz o problema ao problema de [[https://en.wikipedia.org/wiki/Levenshtein_distance][distância de edição]] (e,
  portanto, que pode ser resolvido com o clássico algoritmo de
  [[https://en.wikipedia.org/wiki/Needleman%E2%80%93Wunsch_algorithm][Needleman-Wunsch]]).

* UVA 11258 String Partition

  Se você nunca estudou PD, estude (comece pelas seções respectivas nos
  livros do Cormen, do Skiena e dos Halim). Após estudar, com certeza
  você vai conseguir resolver este problema com PD sem maiores
  dificuldades. Dica: perceba que tudo gira em torno das escolhas entre
  particionar o número a partir de uma posição e não particionar ;)

  - Complexidade: $O(m^2)$ para cada caso de teste, sendo $m$ o número de
    dígitos do inteiro fornecido naquele caso de teste.

* UVA 10891 Game of Sum

  #+BEGIN_QUOTE
  /Dicas escritas por Alesom Zorzi./
  #+END_QUOTE

  É bem claro que é uma PD, o próprio exemplo explica isso. Tentei fazer
  alternando os turnos, mas na realidade da para perceber que não importa
  em qual turno estamos, já que ambos os jogadores querem tomar o máximo
  possível. A diferença é que $S[i][j]$ guarda o valor apenas do Player
  1 já
  que o esse valor é possível facilmente obter o valor do player 2 para
  fazer a subtração. Um esboço da PD:

  #+BEGIN_SRC cpp
  pd(x, y)
    if (x==y) return valor[x];
    for (i =x; i < y;i++)
      resp = max(resp, tomar i - x + 1 elementos da esquerda para a direita);
    for (i = y; i > x;i--)
      resp = max(resp, tomar y - i +1 elementos da direita para a esquerda);
    resp = max(resp, tomar todos os elementos de x até y);
    return S[i][j] = resp;
  #+END_SRC

  - Complexidade: $O(N^3)$, já que são $N^2/2$ estados e a computação de
    cada estado requer tempo $O(N)$.

* UVA 11610 Reverse Prime

  #+BEGIN_QUOTE
  /Dicas escritas por Matheus Dall Rosa./
  #+END_QUOTE

      Primeiro calculamos todos os primos até $10^6$ com o crivo de
      Eratóstenes, e então para computar os primos
    reversos podemos verificar se o reverso de cada inteiro no intervalo
    $[10^6,10^7]$ é um número primo menor que
    $10^6$.

    Para respondermos a operação /query/ podemos utilizar uma BIT e para
    calcular a soma acumulada dos fatores
    primos de todos os primos reversos em $O(\log(N))$
    onde $N$ é a quantidade de primos reversos.

    Para processarmos a operação /deletion/ devemos remover o número de
    fatores primos deste primo reverso da
    BIT.

    Também devemos removê-lo da lista de primos reversos, podemos fazer
    está operação em $O(N)$, visto que o
    número de operações do tipo /deletion/ é no máximo 3500 e como o número de
    primos reversos no intervalo dado é
    aproximadamente 79000 então temos: $3500*79000 = 276500000$, um algoritmo
    com esta complexidade provavelmente não passaria se o problema
    tivesse multiplos casos de teste porém o problema em questão só
    possui um caso de teste.

    - Complexidade: Assim teremos $O(Q*log(N))$ para responder as
      operações do tipo /query/ e $O(D*N)$ para responder todas as
      operações do tipo /deletion/.

* URI 1634 Another Lottery

  #+BEGIN_QUOTE
  /Dicas escritas por Leonardo Blanger./
  #+END_QUOTE

  A chave do problema é perceber que, devido ao prêmio dobrar a cada
  round, o prêmio no último round vai ser maior do que a soma de todos os
  anteriores. Portanto, o proplema se resume a encontrar a probabilidade
  de cada apostador vencer o último round, que é dada pela quantidade de
  bilhetes comprado pelo apostador no último round, dividido pelo total de
  bilhetes vendidos no último round. (Lembrando que a resposta precisa ser
  uma fração simplificada).

  - Complexidade: $O(n)$

* URI 2014 Blood Groups

  #+BEGIN_QUOTE
  /Dicas escritas por Alesom Zorzi./
  #+END_QUOTE

Este problema é bem confuso, demorei mesmo para entender o que ele
pedia. Mas depois de ler algumas vezes e montar os casos com muuuita
calma, percebi que ele quer apenas verificar se existe um emparelhamento
perfeito em um grafo-bipartido (vide
[[http://moreno.cin.ufpe.br/~if775/2013.1/ppt/Emparelhamento%20emGrafosBipartidos.pdf][aqui]]). Para o emparelhamento máximo no grafo bipartido, eu usei o
algoritmo de Hopcroft-Karp que é um algoritmo mais eficiente para
encontrar o emparelhamento máximo em grafos bipartidos (quando comparado
aos métodos mais simples). Mas como ônus é mais complicado também, o
algoritmo pode ser encontrado
[[http://moreno.cin.ufpe.br/~if775/2013.1/ppt/Emparelhamento%20emGrafosBipartidos.pdf][aqui]] e na Seção 9.10 do livro dos Halim.

Forme o grafo $G$, com $V(G) = A\cup B$ da seguinte forma:
A partição $A$ do grafo terá $N$
 vértices e cada vértice será um dos pais;
A partição $B$ também terá $N$
 vértices, mas estes vértices serão os $N$
 alelos do possível tipo sanguíneo.

Vai ter aresta $uv$ com $u \in A$ e $v \in B$ se $u$ pode doar o alelo
$v$.

Depois é só verificar o emparelhamento máximo no grafo $G$
 e ver se o tamanho desse emparelhamento é igual a $N$.

- Complexidade: A complexidade do algoritmo fica:
  $O(Q*(N^2+|E|\sqrt{|V|}))=O(Q*N^2\sqrt N)$, já que $|V|=O(N)$ e
  $|E|=O(N^2)$.

* URI 1671 Code

Sendo $G$ o grafo definido no próprio enunciado do problema, perceba que
qualquer [[https://en.wikipedia.org/wiki/Eulerian_trail][trilha euleriana]] em $G$ define exatamente o que o problema pede
como resposta. Para computar uma trilha euleriana num grafo, existem
vários algoritmos, sendo o mais eficiente o Algoritmo de Hierholzer, que
pode ser implementado com listas duplamente encadeadas em tempo linear
no tamanho do grafo.
 O livro dos Halim (3^a edição)
 apresenta no início da página 180
 uma implementação quadrática no tamanho do grafo
para o Algoritmo de Hierholzer.
Neste problema em particular, você não precisa construir o grafo
explicitamente, e implementar o Algoritmo de Hierholzer pode ficar até
mais fácil assim.

- Complexidade: utilizando uma implementação linear para o Algoritmo de
  Hierholzer:
  $O(\lvert V\rvert+\lvert E\rvert) = O(10^{n-1}+10\times
  10^{n-1})=O(10^n)$, o que é factível, já que $n\leq 6$; utilizando
  um ~set~ para lembrar quais arestas já foram visitadas:
  $O((\lvert V\rvert+\lvert E\rvert)\log\lvert E\rvert) = O(n\times
  10^n)$.

* URI 1748 Fence the Vegetables

  Este foi o Problema F da Nacional de 2014. Veja a discussão
  sobre ele [[http://codeforces.com/blog/entry/14650][neste link]].

* URI 2007 Fence the Vegetables Fail

  #+BEGIN_QUOTE
  /Dicas escritas por Alesom Zorzi./
  #+END_QUOTE

  Esse problema é difícil, de 0 a 10 eu daria um 8. Tem muitos truques
  de implementação que é difícil se ater na hora da competição. Apesar
  do problema parecer de Geometria (verificar se um ponto esta dentro de
  um polígono, não necessariamente convexo) os limites de entrada são
  realmente muito grandes $10^5$ vértices e $10^5$ pontos. Então é
  necessário pensar em outra abordagem: O que facilita é o fato de todas
  as arestas serem paralelas aos eixos. Assim podemos usar uma técnica
  de Line Sweep (vide [[https://www.topcoder.com/community/data-science/data-science-tutorials/line-sweep-algorithms/][aqui]] e [[https://en.wikipedia.org/wiki/Sweep_line_algorithm][aqui]]).

  Assim, a abordagem que eu usei foi:
  Primeiro, podemos notar que basta olhar para as arestas do polígono que
  são paralelas ao eixo $x$. Armazene então todas as arestas paralelas ao
  eixo dos $x$ (note que isso implica que todos os vértices do polígono
  serão armazenados).

  Agora passe uma "linha" por todos os pontos (incluindo os vértices do
  polígono) em ordem de $x$. Então teremos três casos: A linha encosta
  em um
  vértice que é inicio de uma aresta; A linha encosta em um vértice que é
  final de uma aresta; A linha encosta em um ponto $p$.
  Se o primeiro caso
  acontecer, devemos adicionar a aresta em um conjunto de arestas $S$ que
  estão ativas. Se o segundo caso acontecer devemos remover a aresta de
  $S$. Se o terceiro caso acontecer devemos verificar entre quais arestas
  está o ponto $p$ e contar ou não esse ponto para a resposta. Mas a
  realidade é que apenas precisamos saber quantas arestas ativas existem
  antes (ou depois) do ponto. Se existe um número par de arestas antes
  dele quer dizer que ele está fora do polígono, se não esta dentro do
  polígono.

  Note que precisamos realizar as atualizações, remoções e consultas de
  forma bastante eficaz (não pode ser linear, já estamos usando tempo
  linear para o line sweep, ficaria $10^5 * 10^5 + 10 ^5 / 2$ no pior
  dos casos), então vamos recorrer a boa e velha BIT (ou Fenwick tree)
  (vide [[https://en.wikipedia.org/wiki/Fenwick_tree][aqui]] e [[https://www.topcoder.com/community/data-science/data-science-tutorials/binary-indexed-trees/][aqui]]). Assim, a cada vez que inserirmos alguma aresta a
  no conjunto $S$ iremos dar um update na BIT no lugar onde esta o valor
  que representa a aresta $a$ em $S$. Para pesquisar, apenas verificamos
  quantas arestas existem antes do ponto p com uma quer y na BIT.

  Lindo né? Não. Já que os valores de $x$ e $y$ podem ir de $-10^9$ até
  $10^9$. Mas como o número de pontos e vértices somados tem no máximo
  tamanho de $2*10^5$ podemos usar uma "compactação" para o $y$ de todos
  os elementos (vértices e pontos). Apenas ordene por ordem de $y$ as
  arestas e os pontos. Percorra o vetor e dê valores de 1 até $N$, sendo
  $N$
  o número total de elementos no vetor. Agora sim podemos usar a BIT
  para fazer as atualizações e consultas.

  - Complexidade $N\log(N) = 10^5*log(10^5)$.

* URI 2012 Height Map

  Este foi o Problema H da Nacional de 2015. Veja a discussão
  sobre ele [[https://chococontest.wordpress.com/2015/11/23/solucionario-regional-south-america-2015/][neste link]].

* URI 1752 Journey Through The Kingdom

  Este foi o Problema J da Nacional de 2014. Veja a discussão
  sobre ele [[http://codeforces.com/blog/entry/14650][neste link]].

* URI 2009 Just a bit sorted

  Este foi o Problema J da Nacional de 2015. Veja a discussão
  sobre ele [[https://chococontest.wordpress.com/2015/11/23/solucionario-regional-south-america-2015/][neste link]].

* URI 2030 Pit Stop

  Problema /ad hoc/ fácil ;)

* URI 2031 Rock, Paper, Airstrike

  Problema /ad hoc/ muito fácil ;)

* UVA 13049 Combination Lock

  #+BEGIN_QUOTE
  /Dicas escritas por Kétly Machado./
  #+END_QUOTE

Para solucionar este problema, basta olharmos para cada combinação
~Initial~ e ~Target~ e computarmos a resposta da seguinte forma:

  #+BEGIN_SRC cpp
  resposta = 0
  Para todo i de 0 até n faça
    resposta = resposta + min(número de movimentos para se alcançar Target[i] a partir de Inicial[i] girando no sentido horário,
                              número de movimentos para se alcançar Target[i] a partir de Inicial[i] girando no sentido anti-horário)
  #+END_SRC

- Complexidade: $O(n)$

* UVA 11094 Continents

  Dicas podem ser encontradas na página 137 do livro dos Halim (3^a
  edição).

* UVA 11357 Ensuring Truth

  #+BEGIN_QUOTE
  /Dicas escritas por Alesom Zorzi./
  #+END_QUOTE

  Este é um problema simples, dado uma expressão booleana na [[https://en.wikipedia.org/wiki/Disjunctive_normal_form][DNF]], você
precisa dizer se existe um conjunto de valores binários
 $v_1, v_2, \dotsc,v_n$
 que, quando aplicado às variáveis $va_1, va_2, \dotsc, va_n $ da
expressão booleana que é dada na entrada, faz com que tal expressão
tenha como valor final Verdadeiro (ou 1, ou true, entenda como quiser),
ou seja, dizer se a expressão é satisfatível.

Como a forma normal é na DNF, sabemos que apenas uma das cláusulas
precisa ser verdadeira, e para uma clausula ser verdadeira é necessário
que todos as suas variáveis tenham valores positivos, ou seja, a
variável  $va_1$ precisa receber um valor 1 (ou verdadeiro), já a
variável ${\sim}va_1$ precisa receber um valor 0 (ou falso). Ou seja, é um
problema guloso (/greedy/), o que significa que podemos sempre
escolher o melhor
localmente e isto conduzirá à melhor escolha do todo.

Então, o que precisamos fazer é testar para toda cláusula se
é possível
atribuir valores às variáveis de forma que não haja conflitos entre a
valoração das variáveis. Se em uma cláusula isso é possível, então, a
resposta é ~YES~. Se em nenhuma das clausulas isso é possível, então, a
resposta é ~NO~.

- Complexidade: $O(n)$, sendo $n$ o número de caracteres lidos na entrada.

P.S.: Uma dica para a leitura da entrada é: Guarde as cláusulas
separadas, em vetores de pares por exemplo, onde o par é
~variável/valorNecessário~. ~valorNecessário~ é 1 se a variável
 não tiver um
sinal de $\sim$
 no caractere anterior e 0 se tiver. Quando ler um '~(~', inicie
um novo vetor de pares ~variável/valorNecessário~ e só termine o vetor
quando ler um '~)~'. Deste modo fica mais fácil de verificar se existe
conflito entre duas variáveis na mesma clausula.

* UVA 11475 Extend to Palindromes

  #+BEGIN_QUOTE
  /Dicas escritas por Kétly Machado./
  #+END_QUOTE

Seja $S$ a string original dada na entrada, indexada de $0$ até
$tam(S) - 1$, para solucionar este problema precisamos encontrar a maior
substring $S'$ de $S$ que contenha $S[tam(S) - 1]$ e seja um
palíndromo. Encontrada $S'$, dada pelos caracteres $S[i]$ até
$S[tam(S) - 1]$, a resposta é dada pela concatenação de $S$ com a
substring $S''$ invertida, sendo $S''$ dada pelos caracteres $S[0]$ até
$S[i - 1]$ (se $i - 1 < 0$, então $S''$ é uma string vazia).

Para encontrar $S'$ é possível utilizar uma busca linear na string $S$,
testando para cada $S[i] = S[tam(S) - 1]$ se a substring dada pelos
caracteres $S[i]$ até $S[tam - 1]$ forma um palíndromo.

- Complexidade: Embora acredite que esta solução no pior caso tenha
  complexidade $O(n * (n + 1) / 2) = O(n^2)$ e, teoricamente não passe,
  já que $n <= 10^5$, a mesma foi suficiente para atender às entradas do
  UVA.

* UVA 622 Grammar Evaluation

  Dicas podem ser encontradas na página 239 do livro dos Halim (3^a
  edição).

* UVA 10859 Placing Lampposts

  Tente se inspirar na PD para o Problema de Cobertura Mínima por
  Vértices (/MVC: Minimum Vertex Cover/) _em árvores_, muito bem
  explicada nas páginas 175--176 do livro dos Halim (3^a edição).

* UVA 12542 Prime Substring

  Dicas podem ser encontradas na página 203 do livro dos Halim (3^a
  edição).

* UVA 13026 Search the Khoj

  #+BEGIN_QUOTE
  /Dicas escritas por Kétly Machado./
  #+END_QUOTE

Neste problema, para cada telefone presente na agenda do pai de Khoj, é
realizada a comparação com o telefone memorizado por Khoj, avaliando
para cada caractere $a$ do \(i\)-ésimo telefone da agenda e cada caractere
\(k\) do telefone memorizado por Khoj se $a = k$. Seja $f$ o número de
vezes em que a comparação é falsa, se $f \leq 1$ então o \(i\)-ésimo
telefone da agenda pode ser impresso na saída. Devemos realizar esse
procedimento para todo $i$ de $1$ até $n$.

- Complexidade: Seja $t$ o tamanho padrão dos telefones da agenda e do
  telefone memorizado por Khoj, temos uma complexidade de $O(nt)$, como $n
  \leq 10^3$ e $t \leq 11$, temos uma complexidade da ordem de $10^4$, que
  passa tranquilamente.

* UVA 11319 Stupid Sequence?

  Dicas podem ser encontradas na página 348 do livro dos Halim (3^a
  edição).

* UVA 488 Triangle Wave

  Dicas podem ser encontradas na página 239 do livro dos Halim (3^a
  edição).

* LA 5057 Worst Location

  Este foi o problema A da Regional de Jakarta 2010. Dicas podem ser
  encontradas [[http://www.suhendry.net/blog/?p=1389][aqui]].

* LA 5058 Counting BST

  #+BEGIN_QUOTE
  /Dicas escritas por Leonardo Blanger./
  #+END_QUOTE

  Problema bem legal de combinatória. Existem
  $\binom M N =\frac{M!}{(M-N)!N!}$
  subconjuntos de valores que podem ser
  escolhidos. Suponha que tenhamos escolhidos um deles, então precisamos,
  para cada nó da árvore, recuperar a quantidade de valores na sub-árvore
  esquerda e na subárvore direita e encontrar de quantas formas podemos
  organizar estes valores, de forma que a ordem dos valores da subárvore
  esquerda e direita seja preservada. Podemos fazer isto recursivamente e
  com a ajuda de uma programação dinâmica. Ao final, basta multiplicar
  este valor por $\binom M N$ e temos a resposta.

- Complexidade: A complexidade de calcular a quantidade de ordens
  possíveis, dados a
  quantidade de valores na esquerda e na direita pode ser feita em
  $O(N)$, levando em conta todos os casos de teste. A contagem para cada
  nó é constante para cada nó. O cálculo das combinações
  pode ser feito em tempo constante se os
  fatoriais e seus inversos multiplicativos forem calculados antes dos
  casos de teste.

* LA 5059 Playing With Stones

  Este foi o problema C da Regional de Jakarta 2010. Dicas podem ser
  encontradas [[http://www.suhendry.net/blog/?p=1389][aqui]].

* LA 5060 Arm Wrestling Tournament

  Este foi o problema D da Regional de Jakarta 2010. Dicas podem ser
  encontradas [[http://www.suhendry.net/blog/?p=1389][aqui]].

* LA 5061 Lightning Energy Report

  Este foi o problema E da Regional de Jakarta 2010. Dicas podem ser
  encontradas [[http://www.suhendry.net/blog/?p=1389][aqui]].

* LA 5062 Transitive Closure

  Este foi o problema F da Regional de Jakarta 2010. Dicas podem ser
  encontradas [[http://www.suhendry.net/blog/?p=1389][aqui]].

* LA 5063 Just Sum It

  Este foi o problema G da Regional de Jakarta 2010. Dicas podem ser
  encontradas [[http://www.suhendry.net/blog/?p=1389][aqui]].

* LA 5064 Serial Numbers

  Este foi o problema H da Regional de Jakarta 2010. Dicas podem ser
  encontradas [[http://www.suhendry.net/blog/?p=1389][aqui]].

* LA 5065 Romantic Date

  Este foi o problema I da Regional de Jakarta 2010. Dicas podem ser
  encontradas [[http://www.suhendry.net/blog/?p=1389][aqui]].

* LA 5066 Fire Drill

  #+BEGIN_QUOTE
  /Dicas escritas por Leonardo Blanger./
  #+END_QUOTE

  Este problema pode ser resolvido com uma combinação de uma busca em
  largura (BFS) para calcular a distância das células até a saída e de
  uma programação dinâmica para decidir quais voluntários
  escolher. Quando um voluntário for escolhido é preciso ir até ele e
  carregá-lo de volta, portanto, custo de escolher um voluntário é 3
  vezes a distância dele até a saída.

  - Complexidade: A busca possui complexidade linear, enquanto a PD é
    $O(NS)$.

* URI 1912 Help Seu Madruga

  #+BEGIN_QUOTE
  /Dicas escritas por João Winckler./
  #+END_QUOTE

  Queremos encontrar a altura onde Seu Madruga deve fazer o corte, para
  tal usamos uma busca binária. A altura do corte, se for possível, vai
  estar entre 0 e a altura máxima dos papéis. Quando fazemos busca
  binária em um valor double, ao invés de compararmos se o inicio é menor
  ou igual ao fim para abortarmos a busca, repetimos o algoritmo X vezes, que
  sabemos que será o suficiente para conseguirmos a resposta correta. Ao
  fim da busca, checamos se a área formada pelo corte é igual a
  área desejada com o erro de precisão de 4 casas decimais. Para fazer isso,
  subtraímos a área obtida com o corte da área desejada, se o valor
  absoluto do resultado for menor a 10^{-4}, a resposta está
  correta. Caso contrário, é impossível fazer um corte que resulte na
  área desejada.

  - Complexidade: A busca binária tem complexidade $O(\log N)$, mas para
    cada busca devemos passar por todos os papéis para descobrir qual é a área
    formada pelo corte, resultando na complexidade $O(N\log N)$.

* URI 1856 Arya's Death List

  #+BEGIN_QUOTE
  /Dicas escritas por Matheus Dall Rosa./
  #+END_QUOTE

  Este problema pode ser resolvido utilizando setorização por raiz
  quadrada. Esta técnica consiste na separação de um vetor de tamanho N
  em aproximadamente $\frac{N}{\sqrt{N}}$ setores de tamanho
  $\sqrt{N}$, assim podemos iterar sobre todos os setores em $O(\sqrt{N})$,
  cada setor pode ser representado por uma struct que possui o id da
  primeira pessoa do setor, o id da última pessoa do setor e a
  quantidade de pessoas pertencentes a este setor, o que vai ser útil
  para podermos efetuar a respota da query de tipo Q.

  Antes de começarmos a responder as operações devemos pré-processar o
  vetor de pessoas da entrada, primeiramente mapearemos cada pessoa do
  intervalo $1..10^9$ para o intervalo $1..5 \cdot 10^4$, o que pode ser feito
  através de um map, cada id após ser mapeado deve ser inserido em uma
  lista encadeada e o seu iterador deve ser armazenado em um vetor de
  iteradores IDX[$1..5 \cdot 10^4$], o id de seu setor também deve ser salvo em
  um vetor setID[$1..5 \cdot 10^4$].

  Resposta da query do tipo R e:
  Primeiramente buscamos o identificador de e no intervalo $1..5 \cdot 10^4$
  chamaremos este identificador de ei, e então buscamos o iterador de ei
  em IDX[ei] para fazermos a remoção da pessoa da lista encadeada e
  então a remoção da pessoa do próprio map utilizado para o mapeamento,
  devemos também diminuir a quantia de pessoas no intervalo ao qual ei
  pertence e também resolvermos alguns casos de borda por ex: quando ei
  é o primeiro ou último elemento do setor.Complexidade: $O(1)$ para
  retirarmos a pessoa da lista e $O(\log{N})$ para retirarmos do map,
  resultando em $O(\log{N})$.

  Resposta da query do tipo I p e:
  Primeiramente buscamos o identificador de p e e no intervalo 1..5
  \cdot 10^5
  chamaremos estes de kp e ke respectivamente, acessamos o iterador de
  ke na lista encadeada através de IDX[ke] e então inserimos kp a frente
  de ke na lista, após isso devemos inserir kp no primeiro setor com id
  maior ou igual ao setID[kp] que possui espaço livre, esta parte da
  operação exige o controle sobre o tamanho do setor e também se
  precisamos de um novo setor, após encontramos um setor livre devemos
  incrementar sua quantidade. Complexidade: Por causa da procura por um
  setor com espaço livre esta operação pode custar no pior caso
  $O(\sqrt{N})$, também devemos buscar os identificadores o que custa
  $O(\log{N})$, resultando em $O(\sqrt{N} + \log{N})$.

  Resposta da query do tipo Q a b:
  Primeiramente buscamos o identificador de a e b no intervalo $1..5
  \cdot 10^5$ chamaremos estes de ka e kb respectivamente, acessamos os
  ids de seus setores em setID[ka] e setID[kb] fazemos a varredura de
  todos os setores neste no intervarlo setID[ka]..setID[kb] fazendo a
  contagem do total de pessoas. Complexidade: No pior caso essa
  varredura pode custar O(sqrt(N)).

  - Complexidade: Com o processamento de todas as Q operações teremos uma
    complexidade final de $O(Q \cdot (\sqrt{N} + \log{N}))$.

  #+BEGIN_QUOTE
  /Dicas escritas por Leonardo Blanger./
  #+END_QUOTE

  Solução alternativa: A princípio, eu pensei em resolver da seguinte
  forma. Ler e armazenar toda a lista inicial e as consultas, sendo que
  para cada comando de inserção, eu inseria o elemento em uma lista
  encadeada (sempre mantendo o iterador de cada valor guardado, para não
  precisar percorrer a lista toda). Para remoções e consultas de
  intervalo, eu não fazia nada.

  No final, todos os elementos que pudessem vir a aparecer no problema
  estariam na lista, em uma ordem relativa com os que estariam ao mesmo
  tempo. Então eu simplesmente itero sobre a lista, desde o início, e
  guardo as posições de cada elemento na lista em um vetor ~pos[]~,
  iniciando em 1.

  Percorrendo a lista inicial e as consultas novamente, para cada inserção
  eu atulizo uma BIT da seguinte forma:

  - Inserção: ~update(pos[p[i]], 1)~
  - Remoção: ~update(pos[e[i]], -1)~
  - E para saber a posição de um elemento: ~query(a[i])~

  Quando eu fizer a query, apenas os que estiverem antes de ~a[i]~, naquele
  suposto momento serão contados.

  De início eu levei WA, até ver a solução do Matheus, em que ele havia
  mapeado os valores para um intervalo menor. Eu fiz o mesmo, substituindo
  cada novo valor a ser inserido por um outro valor, e levei Accept. Isso
  foi preciso porque, pelo viso, um inimigo removido pode voltar para a
  lista em algum momento, substituindo o valor que ele tinha em ~pos[]~.

  As leituras e as inserções na lista, podem ser feitas em tempo linear,
  se for guardado o nó em que cada valor está.

  - Complexidade: Pra percorrer elas novamente atualizando a BIT:
    $O((N+Q)log(n))$

* URI 1852 Stark Direwolves

  #+BEGIN_QUOTE
  /Dicas escritas por Leonardo Blanger./
  #+END_QUOTE

  Este problema é uma aplicação do Stable Matching Problem.
Como estamos dando preferência para as crianças, o algoritmo funciona assim:
Enquanto houver uma criança sem lobo, que ainda não tiver percorrido toda a sua lista de lobos, tentar associar esta criança com o melhor lobo possível. Se este lobo estiver livre, associa-se eles, se não, confere-se se a preferência do lobo por esta criança for maior do que a preferência pela criança com que ele está associado atualmente. Se sim, a criança com que o lobo está associado se torna livre, e a criança atual se associa com este lobo.

  - Complexidade: De acordo com a Wikipedia, a complexidade é de
    $O(n^2)$. [[https://en.wikipedia.org/wiki/Stable_marriage_problem][link]]


* LA 7580 Forever Young

  #+BEGIN_QUOTE
  /Dicas escritas por Leonardo Blanger./
  #+END_QUOTE

  Aplicando força bruta nos casos de exemplo, dá pra ver que conforme a
base aumenta, o número $y$ nessa base aparenta ser cada vez maior.
A minha solução foi aplicar uma busca binária pra encontrar a maior
base, em que o valor que ela gera confertendo $y$ fosse o menor
possível, respeitando que seja menor ou igual a $l$. Então, eu fiz uma
função recursiva, que pega um intervalo de bases e uma posição $p$ no
número convertido, e para cada dígito $d$ de 0 até 9, faz outra busca
binária pra encontrar o intervalo das bases em que o dígito na posição
$p$ é igual a $d$, então chama novamente essa função com este intervalo
e a próxima posição. A função para quando a posição fica maior do que o
maior comprimento de número possível (19).

  - Complexidade: Encontrar a base máxima: $O(\log_2(n))$. A complexidade
    da recursão: $O(19 \cdot 10 \cdot \log_2(n))$. Aqui o $n$ é o intervalo total
    das bases, no pior caso $[2, 10^{18}]$.

* CF 670D{1, 2} Magic Powder

  #+BEGIN_QUOTE
  /Dicas escritas por Leonardo Blanger./
  #+END_QUOTE

As duas versões do problema podem ser resolvidas usando uma busca
binária para encontrar a quantidade máxima de cookies que é possível
produzir. Iniciando a busca com o intervalo de 0 até um valor maior que
todas as respostas possíveis, como $10^{10}$. A cada iteração da busca,
testando se é possível produzir a quantidade média do intervalo atual
com os ingredientes iniciais, adicionando, se necessário, o pó
especial. Se for possível fazer isto usando uma quantidade de pó
especial menor ou igual a $k$, então, este ponto médio é uma resposta
candidata, e corto a metade menor do intervalo, caso contrário, corto a
metade de cima do intervalo e procuro por uma quantidade menor de
cookies.

A complexidade da busca é $O(\log_2(m))$, onde m é o tamanho do intervalo
inicial, como eu usei um sempre o valor $10^{10}$, isso é mais ou
menos 32. A complexidade do teste em cada iteração é linear e m $n$.

  - Complexidade: $O(n\log_2(n))$.

* URI 2036 Efeito Dominó

  #+BEGIN_QUOTE
  /Dicas escritas por Leonardo Blanger./
  #+END_QUOTE

Dá pra resolver com uma PD iterativa, onde cada estado é um par (peca, pos),
sendo que a posição representa a posição da peça anterior. Pra cada estado,
tentar colocar a peça atual em cada posição de [posicao, posicao+H].
Se tentar percorrer todas as posições possíveis para cada peça, vai dar TLE,
então para cada peça, é preciso fazer uma poda, tentando só as posições onde
a peça pode ficar, sem que isto viole as distâncias de antes e depois.

   - Complexidade: $O(N*L*H)$ menos o que dá pra economizar com a poda, onde L é o tamanho total da sequências (soma de todos os Ds).


* URI 2351 Hotel Rewards

 #+BEGIN_QUOTE
  /Dicas escritas por João Paulo Castilho./
 #+END_QUOTE

 Primeiro vamos analisar o seguinte: eu sempre preciso pagar por todos
 os hotéis até $K$. Se eu começar a indexar os hotéis por $0$, o
 primeiro hotel que eu posso não-pegar é o exatamente no índice
 $K$. Isso não vale somente para o hotel no índice $K$, mas sim para
 todos os seus múltiplos, ou seja, sempre no MÍNIMO, a partir deles eu
 posso ter mais um hotel grátis. Por exemplo, com $K = 2$, no índice 0 e
 1, terei que pagar pelo hotel, no índice 2 ganharei mais um ticket, e a
 partir do índice 4 ganharei outro e assim por diante. A solução,
 portanto, consiste em uma varredura linear no vetor, de trás para
 frente, colocando os valores em uma file de prioridades, do maior para
 o menor. Toda vez que eu chegar em um múltiplo de $K$, quer dizer que a
 partir dessa posição eu poderei ter um ticket a mais do que das
 posições pra trás, então tudo que eu tenho que fazer é tirar o primeiro
 hotel que está na fila de prioridades. Fazendo isso até $i = 0$, temos
 na fila os hotéis que deverão ser pagos.

 - Comlexidade: $O(N)$ para percorrer o vetor e $O(log(N)) para cada
   inserção na heap.
